{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 추출\n",
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        \n",
    "        self.stopwords =['이', '있', '하', '것', '들', '그', '되', '수', '이', '보', '않', '없', '나', '사람', '주', '아니', '등', '같', '우리', '때', '년', '가', '한', '지', '대하', '오', '말', '일', '그렇', '위하', '때문', '그것', '두', '말하', '알', '그러나', '받', '못하', '일', '그런', '또', '문제', '더', '사회', '많', '그리고', '좋', '크', '따르', '중', '나오', '가지', '씨', '시키', '만들', '지금', '생각하', '그러', '속', '하나', '집', '살', '모르', '적', '월', '데', '자신', '안', '어떤', '내', '내', '경우', '명', '생각', '시간', '그녀', '다시', '이런', '앞', '보이', '번', '나', '다른', '어떻', '여자', '개', '전', '들', '사실', '이렇', '점', '싶', '말', '정도', '좀', '원', '잘', '통하', '소리', '놓']\n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)      \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence)) \n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 모델 생성 및 그래프 생성\n",
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextRank 알고리즘 적용\n",
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 \n",
    "            link_sum = np.sum(A[:,id])\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextRank Class 구현\n",
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        \n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    \n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "        index.sort()\n",
    "\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        return summary\n",
    "\n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        \n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        #index.sort()\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.동 지중해 천연자원 개발을 두고 그리스와 대치 중인 터키의 레제 프 타이 이 프 에 르도 안 대통령이 키 리아 코스 미 초 타 키스 그리스 총리와 대화 의사를 밝혔다.\n",
      "2.이어 \" 터키는 대화 테이블에서 벗어나지 않을 것\" 이라며 \" 우리가 어떤 틀에서 무엇을 논의할 지가 핵심\" 이라고 덧붙였다.\n",
      "3.에 르도 안 대통령은 동 지중해에서 천연가스 탐사 임무를 수행하던 지질 조사선 ' 오루 츠 레이스' 가 터키 남부 안 탈리아 연안으로 귀환한 것을 언급하면서 \" 외교에 기회를 주자\" 고 말했다.\n",
      "\n",
      "상위 5개 키워드\n",
      "\n",
      "대통령\n",
      "터키\n",
      "지중해\n",
      "총리와\n",
      "키스\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "동지중해 천연자원 개발을 두고 그리스와 대치 중인 터키의 레제프 타이이프 에르도안 대통령이 키리아코스 미초타키스 그리스 총리와 대화 의사를 밝혔다.\n",
    "에르도안 대통령은 19일(현지시간) 기자들과 만난 자리에서 \"선의가 있다면 미초타키스 총리와 만날 수 있다\"며 \"화상 회담을 하거나 제3국에서 회담할 수 있을 것\"이라고 말했다.\n",
    "이어 \"터키는 대화 테이블에서 벗어나지 않을 것\"이라며 \"우리가 어떤 틀에서 무엇을 논의할지가 핵심\"이라고 덧붙였다. 에르도안 대통령은 동지중해에서 천연가스 탐사 임무를 수행하던 지질 조사선 '오루츠 레이스'가 터키 남부 안탈리아 연안으로 귀환한 것을 언급하면서 \"외교에 기회를 주자\"고 말했다.\n",
    "'''\n",
    "textrank = TextRank(text)\n",
    "txtComment = []\n",
    "\n",
    "num = 1;\n",
    "\n",
    "for row in textrank.summarize(3):\n",
    "    txtComment.append(row)\n",
    "    \n",
    "for sentence in txtComment:\n",
    "    print(str(num) + \".\" + sentence)\n",
    "    num = num + 1\n",
    "    \n",
    "print(\"\\n상위 5개 키워드\\n\")\n",
    "for key in textrank.keywords()[:5]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
